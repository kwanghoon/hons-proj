% outline background

% 1. Video games
% 2. Reinforcement learning
% 3. Deep Reinforcement Learning
% 4. Conclusion

\chapter{Background}

\section{Reinforcement Learning}

\subsection{Markov Decision Processes}

\subsection{Model-free Reinforcement Learning}

\subsection{Hierarchical Reinforcement Learning}

\subsection{Deep Reinforcement Learning}

Deep Reinforcement Learning aims to solve the problem of learning policies from
multi-dimensional state representations without having to manually engineer
features and the representation itself.

\subsubsection{Deep Learning}

\section{Research using games}

\subsection{ALE}

\subsection{RTS AI Research}

\subsection{Using StarCraft as a platform}

\section{Summary}

The first part of this chapter has presented the Reinforcement Learning
framework and the Markov Decision Process, a formalisation that allows to study,
analyse and compare reinforcement learning algorithms. In particular we have
reviewed work in model-free reinforcement learning and research focused on
adding some form of hierarchical structure to reinforcement learning as a way to
address the problem of learning complex policies. Additionally we have looked at
recent work that addresses the problem of learning policies from visual
information using deep learning, a powerful set of algorithms for building
generative models that can automatically discover features and that work
surprisingly well for domains when lots of data is available.

The second part of the chapter has focused on reviewing some of the available
videogame platforms that have successfully been used in artificial intelligence
research, looking in particular at Real-Time Strategy games. Finally we have
provided a description of StarCraft and the rationale behind the idea of
transforming it into a fully-fledged agent learning platform.
