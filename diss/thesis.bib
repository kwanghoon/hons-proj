@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={Nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}
@book{Sutton:1998:IRL:551283,
 author = {Sutton, Richard S. and Barto, Andrew G.},
 title = {Introduction to Reinforcement Learning},
 year = {1998},
 isbn = {0262193981},
 edition = {1st},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
}

@article{puterman1990markov,
  title={Markov decision processes},
  author={Puterman, Martin L},
  journal={Handbooks in operations research and management science},
  volume={2},
  pages={331--434},
  year={1990},
  publisher={Elsevier}
}

@article{beard1997galerkin,
  title={Galerkin approximations of the generalized Hamilton-Jacobi-Bellman equation},
  author={Beard, Randal W and Saridis, George N and Wen, John T},
  journal={Automatica},
  volume={33},
  number={12},
  pages={2159--2177},
  year={1997},
  publisher={Elsevier}
}

@article{kaelbling1996reinforcement,
  title={Reinforcement learning: A survey},
  author={Kaelbling, Leslie Pack and Littman, Michael L and Moore, Andrew W},
  journal={Journal of artificial intelligence research},
  pages={237--285},
  year={1996}
}

@article{doya2000reinforcement,
  title={Reinforcement learning in continuous time and space},
  author={Doya, Kenji},
  journal={Neural computation},
  volume={12},
  number={1},
  pages={219--245},
  year={2000},
  publisher={MIT Press}
}

@article{minsky1961steps,
  title={Steps toward artificial intelligence},
  author={Minsky, Marvin},
  journal={Proceedings of the IRE},
  volume={49},
  number={1},
  pages={8--30},
  year={1961},
  publisher={IEEE}
}

@article{silver2009reinforcement,
  title={Reinforcement learning and simulation-based search},
  author={Silver, David},
  journal={Doctor of philosophy, University of Alberta},
  year={2009}
}

@article{tesauro1995temporal,
  title={Temporal difference learning and TD-Gammon},
  author={Tesauro, Gerald},
  journal={Communications of the ACM},
  volume={38},
  number={3},
  pages={58--68},
  year={1995}
}

@article{campbell2002deep,
  title={Deep blue},
  author={Campbell, Murray and Hoane, A Joseph and Hsu, Feng-hsiung},
  journal={Artificial intelligence},
  volume={134},
  number={1},
  pages={57--83},
  year={2002},
  publisher={Elsevier}
}

@article{kitano1997robocup,
  title={RoboCup: A challenge problem for AI},
  author={Kitano, Hiroaki and Asada, Minoru and Kuniyoshi, Yasuo and Noda, Itsuki and Osawa, Eiichi and Matsubara, Hitoshi},
  journal={AI magazine},
  volume={18},
  number={1},
  pages={73},
  year={1997}
}

@misc{wymann2013torcs,
  title={TORCS, The Open Racing Car Simulator},
  author={Wymann, Bernhard and Espi, E and Guionneau, C and Dimitrakakis, C and Coulom, R and Sumner, A},
  year={2013}
}

@article{bellemare2012arcade,
  title={The arcade learning environment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  year={2012}
}

% --------------- ch2

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves,
                  Alex and Antonoglou, Ioannis and Wierstra, Daan and
                  Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}
@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu,
                  Andrei A and Veness, Joel and Bellemare, Marc G and Graves,
                  Alex and Riedmiller, Martin and Fidjeland, Andreas K and
                  Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}
@inproceedings{buro2003real,
  title={Real-time strategy games: A new AI research challenge},
  author={Buro, Michael},
  booktitle={IJCAI},
  pages={1534--1535},
  year={2003}
}
@book{berry1985bandit,
  title={Bandit problems: sequential allocation of experiments (Monographs on statistics and applied probability)},
  author={Berry, Donald A and Fristedt, Bert},
  year={1985},
  publisher={Springer}
}
@inproceedings{stone2001scaling,
  title={Scaling reinforcement learning toward RoboCup soccer},
  author={Stone, Peter and Sutton, Richard S},
  booktitle={ICML},
  volume={1},
  pages={537--544},
  year={2001}
}
@book{gosavi2014simulation,
  title={Simulation-based optimization: parametric optimization techniques and reinforcement learning},
  author={Gosavi, Abhijit},
  volume={55},
  year={2014},
  publisher={Springer}
}

@article{ponsen2005stratagus,
  title={Stratagus: An open-source game engine for research in real-time strategy games},
  author={Ponsen, Marc JV and Lee-Urban, Stephen and Mu{\~n}oz-Avila, H{\'e}ctor and Aha, David W and Molineaux, Matthew},
  journal={Reasoning, Representation, and Learning in Computer Games},
  pages={78},
  year={2005}
}
@article{levine2015end,
  title={End-to-End Training of Deep Visuomotor Policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1504.00702},
  year={2015}
}
@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={ICML},
  volume=2,
  pages={267--274},
  year=2002
}
@article{bwapi2011brood,
  title = {Brood War Application Programming Interface},
  author = {BWAPI Team},
  year = 2011,
  journal = {bwapi.github.io}
}
@article{pall2008luajit,
  title={The luajit project},
  author={Pall, Mike},
  journal={Web site: http://luajit. org},
  year={2008}
}
@inproceedings{collobert2011torch,
  title={Torch7: A matlab-like environment for machine learning},
  author={Collobert, Ronan and Kavukcuoglu, Koray and Farabet, Cl{\'e}ment},
  booktitle={BigLearn, NIPS Workshop},
  year={2011}
}
@article{nvidia2008programming,
  title={Programming guide},
  author={CUDA},
  year=2008,
  journal={Nvidia}
}
@article{protobuf,
  title={Protocol Buffers},
  author={Google},
  journal={github.com/google/protobuf},
  year=2008
}
@inproceedings{marthi2005concurrent,
  title={Concurrent Hierarchical Reinforcement Learning.},
  author={Marthi, Bhaskara and Russell, Stuart J and Latham, David and Guestrin, Carlos},
  booktitle={IJCAI},
  pages={779--785},
  year={2005}
}
@article{dietterich2000hierarchical,
  title={Hierarchical reinforcement learning with the MAXQ value function decomposition},
  author={Dietterich, Thomas G},
  journal={J. Artif. Intell. Res.(JAIR)},
  volume={13},
  pages={227--303},
  year={2000}
}
@phdthesis{watkins1989learning,
  title={Learning from delayed rewards},
  author={Watkins, Christopher John Cornish Hellaby},
  year={1989},
  school={University of Cambridge England}
}
@inproceedings{stolle2002learning,
  title={Learning options in reinforcement learning},
  author={Stolle, Martin and Precup, Doina},
  organization={Springer}
}

@article{varda2008protocol,
  title={Protocol buffers: Googleâ€™s data interchange format},
  author={Varda, Kenton},
  journal={Google Open Source Blog, Available at least as early as Jul},
  year={2008}
}

@inproceedings{ng2000algorithms,
  title={Algorithms for inverse reinforcement learning.},
  author={Ng, Andrew Y and Russell, Stuart J and others},
  booktitle={Icml},
  pages={663--670},
  year={2000}
}

@inproceedings{russell2003q,
  title={Q-decomposition for reinforcement learning agents},
  author={Russell, Stuart and Zimdars, Andrew},
  booktitle={ICML},
  volume={3},
  pages={656},
  year={2003}
}